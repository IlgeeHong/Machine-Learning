{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elements of Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example) we have an image of a face and want to know if person is smiling <br>\n",
    "\n",
    "Basis Step <br>\n",
    "(1) Collect raw data - e.g., photographs of face <br>\n",
    "(2) Preprocessing - change the data to simplify subsequent operations without losing relevant information - e.g., crop to standard size, only one face per image, assign label to each image, etc <br>\n",
    "(3) Feature extraction - reduce the data by extracting features or properties relevant to learning task (This step is often unnecessary in modern image recognition systems based on deep neural nets) - e.g., only extract the distances between some points on the face <br>\n",
    "(4) Generate training data - large collection of examples we use to learn a model $(x_i,y_i)$ for i=1,...,n <br>\n",
    "(5) Choose a loss function - a measure of how close our model's predictions are to the truth <br>\n",
    "(6) Learn the model - search our collection of candidate models or model parameters that minimizes loss on training data <br>\n",
    "(7) Characterize generalization error - error of our prediction on new data that was not used for training (testing errors $\\approx$ generalization errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectors and Matrices in Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear model for one feature vector can be written as: $$\\hat{y}=<\\mathbf{w},\\mathbf{x_0}>=\\mathbf{w^T}\\mathbf{x_0}=\\mathbf{x_0^T}\\mathbf{w}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define label vector $\\mathbf{y}=\\begin{bmatrix} y_1 \\\\ ... \\\\ y_n \\end{bmatrix}$ and feature matrix $X=\\begin{bmatrix} \\mathbf{x_1^T} \\\\ ... \\\\ \\mathbf{x_n^T} \\end{bmatrix}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the linear model for all training samples can be written as:$$\\mathbf{\\hat{y}}=X\\mathbf{w}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fit the linear model, the relationship between each feature and $y$ should be linear. Let's think of two features ($d=3$) and then our linear model is a plane. However, **when we see the plot in the direction of each feature - $y$ coordinate, we can find the linear line.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the linear model when the relationship between a feature and $y$ is quadratic or cubic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let the feature matrix $X=\\begin{bmatrix} 1 & z_1 & z_1^2 & z_1^3 \\\\ ... &...&...&... \\\\ 1 & z_n & z_n^2 & z_n^3 \\end{bmatrix}$ and matrices with this special structure are called Vandermonde matrices. <br> Then $\\mathbf{\\hat{y}}=X\\mathbf{w}$ implies we have cubic polynomial to fit each training sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e.g., Recommender System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "||A|B|C|D|\n",
    "|:-:|:-:|:-:|:-:|:-:|\n",
    "|Star Wars|10|1|6|5|\n",
    "|Parasite|5|10|8|10|\n",
    "|La la land|1|10|8|10|\n",
    "|Bird Box|8|4|8|5|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write the above table as $X$. Then we can write $X_{n\\times p}$ as the product of two matrices $U_{n\\times r}$ and $V_{r\\times p}$. Think of<br> \n",
    "$U_{n\\times r}$=rating of r representative (extreme) customers to n different movies<br>\n",
    "$V_{r\\times p}$=weights on each representative profile for each p customer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Inner product representation<br>\n",
    "$UV=\\begin{bmatrix} u_1^T \\\\ ... \\\\ u_n^T \\end{bmatrix} \\begin{bmatrix} V_1 & ... & V_p \\end{bmatrix}=\\begin{bmatrix} u_1^T V_1 &...&u_1^T V_p \\\\ ... & & ...\\\\u_n^T V_1 &...&u_n^T V_p  \\end{bmatrix}=\\begin{bmatrix} UV_1 &...& UV_p\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Outer product representation <br>\n",
    "$UV=\\begin{bmatrix} U_1 & ... & U_r \\end{bmatrix}\\begin{bmatrix} v_1^T \\\\ ... \\\\ v_r^T \\end{bmatrix}=U_1v_1^T+...+U_r v_r^T$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
